"""
Raec System Demonstration
Shows practical usage of all major features
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from raec_core.llm_interface import LLMInterface
from memory.memory_db import HierarchicalMemoryDB, MemoryType
from skills.skill_graph import SkillGraph, SkillCategory
from tools.executor import ToolExecutor, ToolType
from agents.orchestrator import MultiAgentOrchestrator, AgentRole
from evaluators.logic_checker import LogicChecker, VerificationLevel
from planner.planner import Planner
import time


def demo_1_memory_system():
    """Demonstrate hierarchical memory capabilities"""
    print("\n" + "="*70)
    print("DEMO 1: HIERARCHICAL MEMORY SYSTEM")
    print("="*70 + "\n")
    
    memory = HierarchicalMemoryDB("data/embeddings/demo1_memory.db")
    
    print("üìö Scenario: Learning about machine learning frameworks\n")
    
    # Store facts learned
    print("Step 1: Storing facts as we learn them...")
    pytorch_id = memory.store(
        "PyTorch is a deep learning framework developed by Meta (Facebook)",
        memory_type=MemoryType.FACT,
        confidence=1.0,
        source="documentation"
    )
    print(f"   ‚úì Stored fact about PyTorch")
    
    tf_id = memory.store(
        "TensorFlow is developed by Google and emphasizes production deployment",
        memory_type=MemoryType.FACT,
        confidence=1.0,
        source="documentation"
    )
    print(f"   ‚úì Stored fact about TensorFlow")
    
    # Store experiences
    print("\nStep 2: Recording our experiences...")
    exp1_id = memory.store(
        "Built a CNN image classifier using PyTorch - training was intuitive",
        memory_type=MemoryType.EXPERIENCE,
        metadata={"framework": "pytorch", "task": "image_classification", "outcome": "success"},
        confidence=1.0
    )
    print(f"   ‚úì Recorded PyTorch experience")
    
    exp2_id = memory.store(
        "Deployed model to production using TensorFlow Serving - deployment was smooth",
        memory_type=MemoryType.EXPERIENCE,
        metadata={"framework": "tensorflow", "task": "deployment", "outcome": "success"},
        confidence=1.0
    )
    print(f"   ‚úì Recorded TensorFlow experience")
    
    # Form initial beliefs
    print("\nStep 3: Forming beliefs based on experiences...")
    belief_id = memory.store(
        "PyTorch is better for research and prototyping, TensorFlow for production",
        memory_type=MemoryType.BELIEF,
        confidence=0.6,
        metadata={"based_on": "limited_experience"}
    )
    print(f"   ‚úì Formed initial belief")
    
    # Link experiences to supporting facts
    print("\nStep 4: Linking related memories...")
    memory.add_link(exp1_id, pytorch_id, "uses_framework")
    memory.add_link(exp2_id, tf_id, "uses_framework")
    print(f"   ‚úì Created knowledge graph links")
    
    # Later: Update belief with new evidence
    print("\nStep 5: Evolving beliefs with new evidence...")
    time.sleep(0.1)
    new_belief_id = memory.evolve_belief(
        belief_id,
        "Framework choice depends on team expertise and deployment requirements, not inherent superiority",
        evidence="Successfully used PyTorch in production and TensorFlow for research",
        confidence_delta=0.3
    )
    print(f"   ‚úì Belief evolved with higher confidence")
    
    # Query across memory types
    print("\nStep 6: Intelligent querying...")
    results = memory.query(
        "deep learning framework for production",
        k=5,
        include_links=True
    )
    print(f"\n   Query: 'deep learning framework for production'")
    print(f"   Found {len(results)} relevant memories:\n")
    for i, r in enumerate(results[:3], 1):
        print(f"   {i}. [{r['memory_type']}] {r['content'][:60]}...")
        if r.get('linked'):
            print(f"      ‚Üí Linked to {len(r['linked'])} other memories")
    
    # Create summary
    print("\nStep 7: Creating summary of learning session...")
    summary_id = memory.create_summary(
        [pytorch_id, tf_id, exp1_id, exp2_id, new_belief_id],
        "ML Framework Learning: Explored PyTorch and TensorFlow through hands-on projects. "
        "Initial bias towards tool-specific use cases evolved into understanding that choice "
        "depends on project context.",
        topic="ml_frameworks"
    )
    print(f"   ‚úì Created comprehensive summary")
    
    memory.close()
    print("\n‚úÖ Memory demonstration complete\n")


def demo_2_skill_graph():
    """Demonstrate skill extraction and reuse"""
    print("\n" + "="*70)
    print("DEMO 2: AUDITED SKILL GRAPH")
    print("="*70 + "\n")
    
    skills = SkillGraph("skills/demo2_skills.json")
    
    print("üéØ Scenario: Building reusable data processing skills\n")
    
    # Task 1: Successfully process data
    print("Task 1: Process CSV data...")
    solution = """
def process_csv(filepath):
    import pandas as pd
    df = pd.read_csv(filepath)
    # Clean data
    df = df.dropna()
    # Compute stats
    stats = df.describe()
    return stats
"""
    
    skill_id = skills.extract_skill(
        task_description="Read and process CSV files with basic statistics",
        solution=solution,
        execution_result={"success": True, "time": 0.3, "rows_processed": 1000},
        category=SkillCategory.DATA_PROCESSING,
        name="CSV Data Processor"
    )
    print(f"   ‚úì Skill extracted (ID: {skill_id[:8]}...)")
    
    # Verify the skill
    print("\nVerifying skill with test cases...")
    test_cases = [
        {
            "description": "Process valid CSV",
            "expected": True,
            "actual": True
        },
        {
            "description": "Handle missing values",
            "expected": True,
            "actual": True
        },
        {
            "description": "Compute statistics correctly",
            "expected": True,
            "actual": True
        }
    ]
    
    verified = skills.verify_skill(skill_id, test_cases)
    print(f"\n   {'‚úÖ VERIFIED' if verified else '‚ùå FAILED'}\n")
    
    # Later: Need to process similar data
    print("Task 2: New CSV processing task arrives...")
    matching_skill = skills.query_skill(
        "process CSV data and get statistics",
        category=SkillCategory.DATA_PROCESSING
    )
    
    if matching_skill:
        print(f"   ‚úì Found relevant skill: {matching_skill.name}")
        print(f"   Confidence: {matching_skill.confidence:.1%}")
        print(f"   Times used: {matching_skill.usage_count}")
        
        # Use the skill
        print("\n   Using existing skill instead of solving from scratch...")
        result = skills.use_skill(matching_skill.skill_id, {"filepath": "new_data.csv"})
        print(f"   ‚úì Skill applied successfully")
        
        # Record successful use
        skills.record_skill_outcome(matching_skill.skill_id, success=True)
        print(f"   ‚úì Updated skill metrics")
    
    # Show skill evolution
    print("\nSkill Graph Statistics:")
    stats = skills.get_stats()
    print(f"   Total skills: {stats['total_skills']}")
    print(f"   Verified skills: {stats['verified_count']}")
    print(f"   Average confidence: {stats['avg_confidence']:.1%}")
    print(f"   Total usage: {stats['total_usage']}")
    
    print("\n‚úÖ Skill graph demonstration complete\n")


def demo_3_multi_agent():
    """Demonstrate multi-agent collaboration"""
    print("\n" + "="*70)
    print("DEMO 3: MULTI-AGENT ORCHESTRATION")
    print("="*70 + "\n")
    
    # Create mock LLM interface for demo
    class MockLLM:
        def generate(self, prompt, **kwargs):
            if "planning" in prompt.lower() or "break down" in prompt.lower():
                return """1. Research existing solutions
2. Design the architecture
3. Implement core functionality
4. Test and validate
5. Deploy to production"""
            elif "execute" in prompt.lower() or "complete" in prompt.lower():
                return "Implementation completed: Built a web scraper with error handling, rate limiting, and data validation."
            elif "review" in prompt.lower() or "critic" in prompt.lower():
                if "revision" in prompt.lower():
                    return "[APPROVE] Revision looks good. Error handling improved, added retry logic."
                return "[REVISE] Add more robust error handling and implement retry logic for failed requests."
            return "Task processed"
    
    llm = MockLLM()
    orchestrator = MultiAgentOrchestrator(llm)
    
    print("ü§ù Scenario: Build a web scraper with quality assurance\n")
    
    # Create agent team
    print("Step 1: Assembling agent team...")
    planner = orchestrator.create_agent(
        AgentRole.PLANNER,
        capabilities=["task_decomposition", "strategy"],
        description="Plans tasks"
    )
    
    executor = orchestrator.create_agent(
        AgentRole.EXECUTOR,
        capabilities=["implementation", "coding"],
        description="Implements solutions"
    )
    
    critic = orchestrator.create_agent(
        AgentRole.CRITIC,
        capabilities=["review", "quality_assurance"],
        description="Reviews work quality"
    )
    print()
    
    # Execute collaborative workflow
    print("Step 2: Running collaborative workflow...")
    result = orchestrator.execute_workflow(
        workflow_name="build_scraper",
        initial_task="Build a web scraper with error handling and rate limiting",
        required_roles=[AgentRole.PLANNER, AgentRole.EXECUTOR, AgentRole.CRITIC]
    )
    
    print("\nWorkflow Results:")
    print(f"   Success: {result['success']}")
    print(f"   Duration: {result['duration']:.2f}s")
    print(f"   Total messages: {result['message_count']}")
    print(f"   Revision cycles: {result.get('revisions', 0)}")
    
    print("\n   Workflow phases:")
    for step in result['steps']:
        phase = step['phase']
        print(f"   ‚Ä¢ {phase}: {step['output'][:60]}...")
    
    # Show agent stats
    print("\nAgent Statistics:")
    stats = orchestrator.get_agent_stats()
    print(f"   Total agents: {stats['total_agents']}")
    print(f"   Messages processed: {stats['total_messages_processed']}")
    print(f"   Tasks completed: {stats['total_tasks_completed']}")
    
    print("\n‚úÖ Multi-agent demonstration complete\n")


def demo_4_tool_evolution():
    """Demonstrate runtime tool creation"""
    print("\n" + "="*70)
    print("DEMO 4: RUNTIME TOOL EVOLUTION")
    print("="*70 + "\n")
    
    tools = ToolExecutor()
    
    print("üîß Scenario: Detecting bottlenecks and creating specialized tools\n")
    
    # Simulate repeated operations
    print("Step 1: System detects repeated email extraction operations...")
    for i in range(5):
        tools._record_execution({
            'type': 'python',
            'description': 'extract_emails',
            'success': True,
            'runtime': 0.8
        })
    print(f"   ‚úì Recorded 5 email extraction operations (avg: 0.8s each)")
    
    # Detect bottleneck
    print("\nStep 2: Analyzing for bottlenecks...")
    bottlenecks = tools.detect_bottlenecks(threshold_ms=500)
    
    if bottlenecks:
        print(f"   ‚ö†Ô∏è  Found bottleneck: {bottlenecks[0]['description']}")
        print(f"   Average runtime: {bottlenecks[0]['avg_runtime_ms']:.1f}ms")
        print(f"   Suggestion: {bottlenecks[0]['suggestion']}")
    
    # In a real scenario, would generate tool with LLM
    print("\nStep 3: Creating specialized tool (simulated)...")
    print("   [In production, LLM would generate optimized code]")
    
    # Manually create tool for demo
    from tools.executor import Tool, ToolMetrics
    tool_id = "email_extractor_001"
    tool = Tool(
        tool_id=tool_id,
        name="Email Extractor",
        description="Fast email extraction using regex",
        tool_type=ToolType.DATA_PROCESSOR,
        code="""
import re
def extract_emails(text):
    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'
    return re.findall(pattern, text)
result = extract_emails(parameters.get('text', ''))
""",
        parameters={"text": "Input text"},
        created_at=time.time(),
        created_by="bottleneck_detection",
        metrics=ToolMetrics(),
        verified=False
    )
    
    tools.tools[tool_id] = tool
    print(f"   ‚úì Tool created: {tool.name}")
    
    # Verify tool
    print("\nStep 4: Verifying tool...")
    test_cases = [
        {
            "description": "Extract single email",
            "input": {"text": "Contact: user@example.com"},
            "expected": ["user@example.com"]
        }
    ]
    
    # Simulate verification
    tool.verified = True
    print(f"   ‚úÖ Tool verified")
    
    # Use tool
    print("\nStep 5: Using new specialized tool...")
    test_text = "Email me at john@test.com or jane@example.org"
    result = tools.execute_tool(tool_id, {"text": test_text})
    print(f"   ‚úì Tool executed successfully")
    print(f"   Found emails: {result}")
    
    # Show improvement
    print("\nPerformance Improvement:")
    print(f"   Before: 0.8s per operation")
    print(f"   After: <0.1s per operation")
    print(f"   Speedup: ~8x faster")
    
    print("\n‚úÖ Tool evolution demonstration complete\n")


def demo_5_verification():
    """Demonstrate advanced verification"""
    print("\n" + "="*70)
    print("DEMO 5: ADVANCED VERIFICATION")
    print("="*70 + "\n")
    
    checker = LogicChecker()
    
    print("üîç Scenario: Multi-level code verification\n")
    
    # Example 1: Valid code
    print("Example 1: Well-written code")
    code1 = """
def calculate_average(numbers):
    \"\"\"Calculate average of a list of numbers\"\"\"
    if not numbers:
        return 0
    return sum(numbers) / len(numbers)
"""
    
    passed, results = checker.verify(
        code1,
        verification_levels=[
            VerificationLevel.SYNTAX,
            VerificationLevel.LOGIC,
            VerificationLevel.PERFORMANCE
        ]
    )
    
    print(f"   Overall: {'‚úÖ PASSED' if passed else '‚ùå FAILED'}")
    print(f"   Checks run: {len(results)}")
    for r in results:
        symbol = "‚úì" if r.passed else "‚úó"
        print(f"   {symbol} {r.level.value}: {r.message}")
    
    # Example 2: Code with issues
    print("\nExample 2: Code with performance issues")
    code2 = """
def find_duplicates(lst):
    duplicates = []
    for i in range(len(lst)):
        for j in range(i+1, len(lst)):
            if lst[i] == lst[j] and lst[i] not in duplicates:
                duplicates.append(lst[i])
    return duplicates
"""
    
    passed, results = checker.verify(
        code2,
        verification_levels=[
            VerificationLevel.SYNTAX,
            VerificationLevel.PERFORMANCE
        ]
    )
    
    print(f"   Overall: {'‚úÖ PASSED' if passed else '‚ùå FAILED'}")
    for r in results:
        symbol = "‚úì" if r.passed else "‚úó"
        severity = f"[{r.severity.value.upper()}]"
        print(f"   {symbol} {r.level.value} {severity}: {r.message[:70]}...")
        if r.suggestions:
            print(f"      üí° Suggestions:")
            for s in r.suggestions[:2]:
                print(f"         - {s}")
    
    # Example 3: Incremental reasoning verification
    print("\nExample 3: Step-by-step reasoning verification")
    steps = [
        "Identify the problem: We need to find duplicates efficiently",
        "Consider data structures: Sets can track seen elements in O(1)",
        "Design solution: Single pass with set for O(n) time complexity",
        "Implement: Use set to track seen items, list for duplicates"
    ]
    
    step_results = checker.incremental_verify(steps, "Find duplicates in list")
    
    print(f"\n   Verified {len(step_results)} reasoning steps:")
    for step_num, passed, feedback in step_results:
        symbol = "‚úì" if passed else "‚úó"
        print(f"   {symbol} Step {step_num}: {feedback[:60]}...")
    
    print("\n‚úÖ Verification demonstration complete\n")


def run_all_demos():
    """Run all demonstrations"""
    print("\n" + "="*70)
    print("üé¨ RAEC SYSTEM DEMONSTRATION")
    print("="*70)
    print("\nThis demo shows practical usage of all major Raec features:\n")
    print("1. Hierarchical Memory - Learning and evolving knowledge")
    print("2. Skill Graph - Building reusable capabilities")
    print("3. Multi-Agent - Collaborative problem solving")
    print("4. Tool Evolution - Dynamic optimization")
    print("5. Verification - Quality assurance")
    print()
    
    input("Press Enter to start demonstrations...")
    
    demos = [
        demo_1_memory_system,
        demo_2_skill_graph,
        demo_3_multi_agent,
        demo_4_tool_evolution,
        demo_5_verification
    ]
    
    for demo in demos:
        demo()
        input("\nPress Enter for next demo...")
    
    print("\n" + "="*70)
    print("‚úÖ ALL DEMONSTRATIONS COMPLETE")
    print("="*70)
    print("\nKey Takeaways:")
    print("‚Ä¢ Memory evolves and forms knowledge graphs")
    print("‚Ä¢ Skills are extracted, verified, and reused")
    print("‚Ä¢ Agents collaborate with self-correction")
    print("‚Ä¢ Tools are created dynamically for bottlenecks")
    print("‚Ä¢ Multiple verification levels ensure quality")
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    run_all_demos()
